{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:Maroon\">Case Study: Usage of Data Science in Entertainment Industry.\n",
    "\n",
    "#### <span style=\"color:Green\">Select optimal advetisement to display in break time for a TV Show, based on what was recently shown in the TV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Maroon\">Naive Classifier (Based on Sum of Indepent Variables)\n",
    "\n",
    "<span style=\"color:Green\">A simple implementation of Naive Classifier, which follows our first conclusions when we look at data. Here we pick independent variables which are highly correlated with dependent variable, and use them for prediction. Since we have all binary variables, and a binary prediciton problem, a Max(Sum(Correlated Independent Variables)) could be a good prediction. \n",
    "\n",
    "<span style=\"color:Green\">__NEVER USE THIS AS FINAL MODEL. THIS IS JUST FOR ILLUSTRATION PURPOSE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas._config.config.option_context at 0x2163a9b4788>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "from scipy.stats import chi2_contingency\n",
    "np.random.seed(0)\n",
    "pd.option_context('display.max_rows', None, 'display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the working directory to the folder\n",
    "direc = os.getcwd()\n",
    "os.chdir(\"..//Data//\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data in pandas dataframe\n",
    "data = pd.read_csv(\"Dataset.csv\")\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependent variable (is given name of target)\n",
    "target = 'h_food_str'\n",
    "# Other dependent variables (These should be dropped from our dataset)\n",
    "dv_list = ['h_alcohol_str', 'h_hot_drink_str', 'h_phone_str']\n",
    "# drop the dv_list from the data (as In future, these labels won't be available to us (dv_list).\n",
    "# Hence, for our modeling purpose, these variables are being dropped from the data.)\n",
    "data = data.drop(dv_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_name</th>\n",
       "      <th>time_offset</th>\n",
       "      <th>r_abies</th>\n",
       "      <th>r_abyssinian</th>\n",
       "      <th>r_accessories</th>\n",
       "      <th>r_accipiter</th>\n",
       "      <th>r_acorn</th>\n",
       "      <th>r_adapter</th>\n",
       "      <th>r_adorable</th>\n",
       "      <th>r_adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>r_zoo</th>\n",
       "      <th>h_food_str</th>\n",
       "      <th>show_name_fresh_meat</th>\n",
       "      <th>show_name_friday_night_dinner</th>\n",
       "      <th>show_name_hollyoaks</th>\n",
       "      <th>show_name_made_in_chelsea</th>\n",
       "      <th>show_name_made_in_chelsea_la</th>\n",
       "      <th>show_name_my_mad_fat_diary</th>\n",
       "      <th>show_name_peep_show</th>\n",
       "      <th>show_name_the_inbetweeners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fresh_meat</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fresh_meat</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fresh_meat</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fresh_meat</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fresh_meat</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1615 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    show_name  time_offset  r_abies  r_abyssinian  r_accessories  r_accipiter  \\\n",
       "0  fresh_meat            1      0.0           0.0            0.0          0.0   \n",
       "1  fresh_meat            2      0.0           0.0            0.0          0.0   \n",
       "2  fresh_meat            3      0.0           0.0            0.0          0.0   \n",
       "3  fresh_meat            4      0.0           0.0            0.0          0.0   \n",
       "4  fresh_meat            5      0.0           0.0            0.0          0.0   \n",
       "\n",
       "   r_acorn  r_adapter  r_adorable  r_adventure  ...  r_zoo  h_food_str  \\\n",
       "0      0.0        0.0         0.0          0.0  ...    0.0           0   \n",
       "1      0.0        0.0         0.0          0.0  ...    0.0           0   \n",
       "2      0.0        0.0         0.0          0.0  ...    0.0           0   \n",
       "3      0.0        0.0         0.0          0.0  ...    0.0           0   \n",
       "4      0.0        0.0         0.0          0.0  ...    0.0           0   \n",
       "\n",
       "   show_name_fresh_meat  show_name_friday_night_dinner  show_name_hollyoaks  \\\n",
       "0                     1                              0                    0   \n",
       "1                     1                              0                    0   \n",
       "2                     1                              0                    0   \n",
       "3                     1                              0                    0   \n",
       "4                     1                              0                    0   \n",
       "\n",
       "   show_name_made_in_chelsea  show_name_made_in_chelsea_la  \\\n",
       "0                          0                             0   \n",
       "1                          0                             0   \n",
       "2                          0                             0   \n",
       "3                          0                             0   \n",
       "4                          0                             0   \n",
       "\n",
       "   show_name_my_mad_fat_diary  show_name_peep_show  show_name_the_inbetweeners  \n",
       "0                           0                    0                           0  \n",
       "1                           0                    0                           0  \n",
       "2                           0                    0                           0  \n",
       "3                           0                    0                           0  \n",
       "4                           0                    0                           0  \n",
       "\n",
       "[5 rows x 1615 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding of 'show_name' variable\n",
    "df1 = pd.get_dummies(data['show_name'], prefix = 'show_name')\n",
    "data = data.join(df1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:Maroon\">Train-Test Split\n",
    "<span style=\"color:Green\">Divide the data in 70:30 ratio for training the model and validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop([target],axis=1), data[target], test_size=0.30, \n",
    "                                                    random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dependent variable: 8.83\n",
      "Test Dependent variable: 8.85\n"
     ]
    }
   ],
   "source": [
    "# Check if the random samples have similar mean\n",
    "print (f\"Train Dependent variable: {np.round(np.mean(y_train)*100,2)}\")\n",
    "print (f\"Test Dependent variable: {np.round(np.mean(y_test)*100,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Blue\">__Comments:__ The means of dependent variable are very similar in test and train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:Maroon\">Part 2: Naive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:Blue\">Here we shall try to look at variables and pick important variables to predict the final outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base model libraries from sklearn\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataframe to a new df\n",
    "data_nv2 = data.copy()\n",
    "\n",
    "# convert the 'show_name' to index\n",
    "data_nv2 =  data_nv2.set_index('show_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values '>0' to '1' in all columns\n",
    "data_nv2 = data_nv2.apply(np.ceil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:Green\">To pick important variables, we shall use concept of Information value and chi2 test of independence:\n",
    "<span style=\"color:Green\">$\\;\\;\\;\\;\\;\\;$Step 1: Calculate Information value for all independent variables w.r.t target variable\n",
    "    \n",
    "<span style=\"color:Green\">$\\;\\;\\;\\;\\;\\;$Step 2: Do Chi2 test of independence for all independent variables w.r.t target variable\n",
    "    \n",
    "<span style=\"color:Green\">$\\;\\;\\;\\;\\;\\;$Step 3: Pick the variables which have p-val <= 0.05 (we are able to reject the null hypothesis of independence)\n",
    "                                                                            \n",
    "<span style=\"color:Green\">$\\;\\;\\;\\;\\;\\;$Step 4: From shortlisted variables, pick the ones which have a normalized cumulative IV of 0.90\n",
    "    \n",
    "<span style=\"color:Green\">$\\;\\;\\;\\;\\;\\;$Step 5: Use these variables to predict the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information Value function\n",
    "def IV_calc(df, independent_var, target_var):\n",
    "    \"\"\"\n",
    "    This function takes three inputs:\n",
    "                     df: dataset\n",
    "        independent_var: Independent variable name\n",
    "             target_var: Dependent variable name\n",
    "            \n",
    "    Output: Function returns the Information value\n",
    "    \"\"\"\n",
    "    dftsum = df[[independent_var,target_var]].groupby(independent_var).sum()\n",
    "    dftsum.columns = [\"Goods\"]\n",
    "    dftcount = df[[independent_var,target_var]].groupby(independent_var).count()\n",
    "    dftcount.columns = [\"Total\"]\n",
    "    dfiv = dftsum.join(dftcount,how='left')\n",
    "    dfiv[\"Bads\"] = dfiv[\"Total\"] - dfiv[\"Goods\"]\n",
    "    dfiv[\"Perct_Goods\"] = dfiv[\"Goods\"]/dfiv[\"Goods\"].sum()\n",
    "    dfiv[\"Perct_Bads\"] = np.where(dfiv[\"Bads\"] > 0, dfiv[\"Bads\"]/dfiv[\"Bads\"].sum(), 0.01)\n",
    "    dfiv[\"WOE\"] = np.log(np.where((dfiv[\"Perct_Goods\"]/dfiv[\"Perct_Bads\"])>0,(dfiv[\"Perct_Goods\"]/dfiv[\"Perct_Bads\"]),1))\n",
    "    dfiv[\"IV\"] = ((dfiv[\"Perct_Goods\"] - dfiv[\"Perct_Bads\"])*dfiv[\"WOE\"])\n",
    "    return max(dfiv[\"IV\"].sum(),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi square test of Independence\n",
    "def Chi2_test_of_Independence(df, independent_var, target_var):\n",
    "    \"\"\"\n",
    "    Null hypothesis: Variables are independent\n",
    "    If p-value <= alpha: significant result, reject null hypothesis (H0) {or infer that variables are dependent}.\n",
    "    If p-value > alpha: not significant result, fail to reject null hypothesis(H0), {or infer variables are independent}\n",
    "    For our case, we shall assume an alpha = 0.05\n",
    "    \"\"\"\n",
    "    crosstab = pd.crosstab(df[independent_var],df[target_var])\n",
    "    stat, p, dof, ex = chi2_contingency(crosstab)\n",
    "    return (p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the independent variables \n",
    "columns = list(data_nv2.columns)\n",
    "columns.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare emply lists to store the value of p-val and IV\n",
    "p_val = [None]*len(columns)\n",
    "IV_val = [None]*len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Information value and conduct Chi2 test of independence for independnet variables\n",
    "for i in range(0,len(columns)):\n",
    "    p_val[i] = Chi2_test_of_Independence(data_nv2, columns[i], target)\n",
    "    IV_val[i] = IV_calc(data_nv2, columns[i], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>iv</th>\n",
       "      <th>p_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time_offset</td>\n",
       "      <td>6.333471e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r_abies</td>\n",
       "      <td>6.396791e-04</td>\n",
       "      <td>0.574729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r_abyssinian</td>\n",
       "      <td>1.753496e-08</td>\n",
       "      <td>0.420564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r_accessories</td>\n",
       "      <td>2.340507e-03</td>\n",
       "      <td>0.074956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r_accipiter</td>\n",
       "      <td>4.383595e-09</td>\n",
       "      <td>0.146953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       variables            iv     p_val\n",
       "0    time_offset  6.333471e-01  1.000000\n",
       "1        r_abies  6.396791e-04  0.574729\n",
       "2   r_abyssinian  1.753496e-08  0.420564\n",
       "3  r_accessories  2.340507e-03  0.074956\n",
       "4    r_accipiter  4.383595e-09  0.146953"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the information in Pandas Dataframe for future use\n",
    "DF_IV_CHI2 = pd.DataFrame(columns)\n",
    "DF_IV_CHI2.columns = [\"variables\"]\n",
    "DF_IV_CHI2[\"iv\"] = IV_val\n",
    "DF_IV_CHI2[\"p_val\"] = p_val\n",
    "DF_IV_CHI2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select variables, which have p-val <= 0.05 (We reject null hypothesis)\n",
    "DF_IV_CHI2_CP = DF_IV_CHI2.copy()\n",
    "DF_IV_CHI2_CP = DF_IV_CHI2_CP[DF_IV_CHI2_CP[\"p_val\"] <= 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the IV val from max to min and take a cumulative sum\n",
    "DF_IV_CHI2_CP = DF_IV_CHI2_CP.sort_values(\"iv\", ascending=False)\n",
    "DF_IV_CHI2_CP[\"Cum_IV\"] = DF_IV_CHI2_CP[\"iv\"].cumsum()/DF_IV_CHI2_CP[\"iv\"].sum()\n",
    "top_vars = list(DF_IV_CHI2_CP[DF_IV_CHI2_CP[\"Cum_IV\"] <= 0.95][\"variables\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['show_name_fresh_meat', 'r_cafeteria', 'r_meal', 'r_dinner', 'r_supper', 'r_food', 'r_restaurant', 'r_food_court', 'r_cafe', 'r_plate', 'r_dish', 'show_name_friday_night_dinner', 'show_name_made_in_chelsea_la', 'r_glass', 'show_name_the_inbetweeners', 'r_hot_pot', 'r_beverage', 'show_name_hollyoaks', 'r_drink', 'r_eating', 'r_car', 'r_lamp', 'r_lampshade', 'r_lighting', 'r_automobile', 'r_breakfast', 'r_swimwear', 'r_downtown', 'r_beard', 'r_wine', 'r_urban', 'r_goblet', 'r_city', 'r_pub', 'r_bar_counter', 'r_alcohol', 'r_bikini', 'r_poster', 'r_lunch', 'r_dirt_road', 'r_gravel', 'r_living_room', 'r_flyer', 'r_building', 'r_table_lamp', 'r_platter', 'r_table', 'r_couch', 'r_brochure', 'r_cup', 'r_apartment', 'r_shelf', 'r_light', 'r_flower', 'r_tablecloth', 'r_conifer', 'r_linen', 'show_name_made_in_chelsea', 'r_field', 'show_name_my_mad_fat_diary', 'r_grass', 'r_dining_table', 'r_vehicle', 'r_underwear', 'r_grassland', 'r_interior_design', 'r_lingerie', 'r_yew', 'r_bra', 'r_blossom', 'r_neighborhood', 'r_sitting', 'r_cookie', 'r_shop', 'r_word', 'r_high_rise', 'r_lab', 'r_town', 'r_fir', 'r_bookcase', 'r_chair', 'r_kitchen', 'r_palm_tree', 'r_fitness', 'r_metropolis', 'r_red_wine', 'r_pantry', 'r_velvet', 'r_text', 'r_office_building', 'r_flora', 'r_glasses', 'r_tabletop', 'r_sink', 'r_bottle', 'r_street', 'r_oven', 'r_logo', 'r_appliance', 'r_spruce', 'r_apartment_building', 'r_path', 'r_wine_glass', 'r_hedge', 'r_crypt', 'r_book', 'r_pine', 'r_reception', 'r_lobby', 'r_sunglasses', 'r_forest', 'r_pottery', 'r_pitcher', 'r_collage', 'r_boutique']\n"
     ]
    }
   ],
   "source": [
    "# Print the top variables\n",
    "print(top_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_related_vars = ['show_name_fresh_meat', 'r_cafeteria', 'r_meal', 'r_dinner', 'r_supper', 'r_food', 'r_restaurant',\n",
    "                     'r_food_court', 'r_cafe', 'r_plate', 'r_dish', 'show_name_friday_night_dinner',\n",
    "                     'show_name_made_in_chelsea_la', 'r_glass', 'show_name_the_inbetweeners', 'r_hot_pot', 'r_beverage', \n",
    "                     'show_name_hollyoaks', 'r_drink', 'r_eating', 'r_breakfast', 'r_beard', 'r_wine', 'r_goblet', \n",
    "                     'r_pub', 'r_bar_counter', 'r_alcohol', 'r_lunch', 'r_platter', 'r_cup', 'r_apartment', \n",
    "                     'show_name_made_in_chelsea', 'show_name_my_mad_fat_diary', 'r_dining_table', 'r_cookie', 'r_kitchen',\n",
    "                     'r_pantry', 'r_glasses', 'r_oven', 'r_wine_glass']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Blue\">__Comment:__ From the top variables, select only variables based on business understanding (i.e. only Food variables). Since, the independent variables used in this model are outcome of a predictive model, this model is a compound model, where error of first model gets compunded in second. Hence, we shall use business logic to identify variables which could have similarity with food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sum_Classifier(BaseEstimator, ClassifierMixin):\n",
    "    def __self__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = np.where(X.sum(axis=1)>0, 1, 0)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sum_Classifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the majority class model\n",
    "sc = Sum_Classifier()\n",
    "sc.fit(X_train[food_related_vars],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediciting the class for training dataset\n",
    "y_train_class_pred = sc.predict(X_train[food_related_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "Performance Metrics for Training Sample\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.12     10573\n",
      "           1       0.09      1.00      0.17      1024\n",
      "\n",
      "    accuracy                           0.15     11597\n",
      "   macro avg       0.55      0.53      0.15     11597\n",
      "weighted avg       0.92      0.15      0.13     11597\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "Predicted    0     1\n",
      "Actual              \n",
      "0          694  9879\n",
      "1            0  1024\n"
     ]
    }
   ],
   "source": [
    "print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "print(\"Performance Metrics for Training Sample\")\n",
    "print(classification_report(y_train, y_train_class_pred))\n",
    "\n",
    "tmp = pd.DataFrame(y_train, columns=[\"Actual\"])\n",
    "tmp[\"Predicted\"] = y_train_class_pred\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"\\nConfusion Matrix\\n\")\n",
    "print(pd.crosstab(tmp[\"Actual\"],tmp[\"Predicted\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Blue\">__Comments:__ For Class==1, though the model has a recall of 1, but the accuracy is only 0.15. Hence not a very good model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediciting the class for training dataset\n",
    "y_test_class_pred = sc.predict(X_test[food_related_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "Performance Metrics for Test Sample\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.13      4531\n",
      "           1       0.09      1.00      0.17       440\n",
      "\n",
      "    accuracy                           0.15      4971\n",
      "   macro avg       0.55      0.53      0.15      4971\n",
      "weighted avg       0.92      0.15      0.13      4971\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "Predicted    0     1\n",
      "Actual              \n",
      "0          315  4216\n",
      "1            0   440\n"
     ]
    }
   ],
   "source": [
    "# Peroformance for test sample:\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "print(\"Performance Metrics for Test Sample\")\n",
    "print(classification_report(y_test, y_test_class_pred))\n",
    "\n",
    "tmp = pd.DataFrame(y_test, columns=[\"Actual\"])\n",
    "tmp[\"Predicted\"] = y_test_class_pred\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"\\nConfusion Matrix\\n\")\n",
    "print(pd.crosstab(tmp[\"Actual\"],tmp[\"Predicted\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Blue\">__Comments:__ For Class == , the model has a recall of 1, but precision and accuracy of only 0.15, which is very low. Hence, not a very good model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
